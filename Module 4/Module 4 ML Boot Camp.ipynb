{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "Module 4 ML Boot Camp.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kf1QadRqbRVB",
        "colab_type": "text"
      },
      "source": [
        "## Module 4 Example\n",
        "\n",
        "The Boston Housing Case\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma_Y-uvibRVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################Initialization############################\n",
        "RANDOM_SEED = 1 # seed value for random number generator             \n",
        "import numpy as np\n",
        "from scipy import stats as st\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import rc\n",
        "import os #manage files\n",
        "import matplotlib.pyplot as plt  #plots\n",
        "from matplotlib import rc\n",
        "import sklearn \n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_squared_error, r2_score # evaluation metrics\n",
        "from sklearn.preprocessing import StandardScaler # used for variable scaling data\n",
        "from sklearn.preprocessing import MinMaxScaler as Scaler # used for variable scaling data\n",
        "from sklearn.tree import DecisionTreeRegressor # Regression tree package\n",
        "from sklearn.ensemble import ExtraTreesRegressor # Extra Trees package (bagging)\n",
        "from sklearn.ensemble import RandomForestRegressor # Random Forest package\n",
        "from sklearn.ensemble import GradientBoostingRegressor # Gradient Boosting package\n",
        "from sklearn.model_selection import KFold\n",
        "import sklearn.linear_model \n",
        "#####################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMFhXLesbRVa",
        "colab_type": "text"
      },
      "source": [
        "## Data Ingest and Curation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKerFtw8bRVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mydata=pd.read_csv('boston.csv')\n",
        "mydata=mydata.drop('neighborhood', 1)\n",
        "mydata2=mydata.apply(lambda x: x+.01)\n",
        "mydata3 = mydata2.transform(lambda x: st.boxcox(x)[0])\n",
        "mydata4 = mydata3.transform(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
        "cols = mydata4.columns.tolist()\n",
        "cols = cols[-1:] + cols[:-1]\n",
        "mydata5=mydata4[cols]\n",
        "model_data=mydata5.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yRNGdvxbRYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Seed value for random number generators to obtain reproducible results\n",
        "RANDOM_SEED = 1\n",
        "\n",
        "# The model input data outside of the modeling method calls\n",
        "names = ['DecisionTree_Regression', 'ExtraTrees_Regression', 'RandomForest_Regression', 'GradientBoosting_Regression']\n",
        "\n",
        "# Specify the set of regression models being evaluated\n",
        "regressors = [DecisionTreeRegressor(criterion='mse', max_features = 10, random_state=RANDOM_SEED), \n",
        "              ExtraTreesRegressor(n_estimators = 100, criterion='mse', max_features = 10, bootstrap=True, n_jobs = -1, random_state = RANDOM_SEED),\n",
        "              RandomForestRegressor(n_estimators = 100, criterion='mse', max_features = 10, bootstrap=True, n_jobs = -1, random_state = RANDOM_SEED),\n",
        "              GradientBoostingRegressor(n_estimators = 100, criterion='mse', max_features = 10, random_state=RANDOM_SEED)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60prrTnRbRYb",
        "colab_type": "text"
      },
      "source": [
        "# Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-RI2FaQbRYf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "7595262f-0b95-4e8a-c920-1b7233b6f9fe"
      },
      "source": [
        "# Establish number of cross folds employed for cross-validation\n",
        "N_FOLDS = 10\n",
        "\n",
        "# Setup numpy array for storing results\n",
        "cv_results = np.zeros((N_FOLDS, len(names)))\n",
        "\n",
        "# Initiate splitting process\n",
        "kf = KFold(n_splits = N_FOLDS, shuffle=False, random_state = RANDOM_SEED)\n",
        "\n",
        "# Check the splitting process by looking at fold observation counts\n",
        "index_for_fold = 0  # Fold count initialized \n",
        "for train_index, test_index in kf.split(model_data):\n",
        "    print('\\nFold index:', index_for_fold, '---------------------------------------------------------------------------------------')\n",
        "\n",
        "# The structure of modeling data for this study has the response variable coming first and explanatory variables later          \n",
        "# so 1:model_data.shape[1] slices for explanatory variables and 0 is the index for the response variable    \n",
        "    X_train = model_data[train_index, 1:model_data.shape[1]]\n",
        "    X_test = model_data[test_index, 1:model_data.shape[1]]\n",
        "    y_train = model_data[train_index, 0]\n",
        "    y_test = model_data[test_index, 0]   \n",
        "\n",
        "    index_for_method = 0  # Method count initialized\n",
        "    for name, reg_model in zip(names, regressors):\n",
        "        reg_model.fit(X_train, y_train)  # Fit on the train set for this fold\n",
        " \n",
        "        # Evaluate on the test set for this fold\n",
        "        y_test_predict = reg_model.predict(X_test)\n",
        "        fold_method_result = sqrt(mean_squared_error(y_test, y_test_predict))\n",
        "        cv_results[index_for_fold, index_for_method] = fold_method_result\n",
        "        index_for_method += 1\n",
        "  \n",
        "    index_for_fold += 1\n",
        "\n",
        "cv_results_df = pd.DataFrame(cv_results)\n",
        "cv_results_df.columns = names\n",
        "\n",
        "print('\\n---------------------------------------------------------------------------------------')\n",
        "print('Average results from ', N_FOLDS, '-fold cross-validation\\n',\n",
        "      'in standardized units (mean 0, standard deviation 1)\\n',\n",
        "      '\\nMethod               Root mean-squared error', sep = '')    \n",
        "print(cv_results_df.mean())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fold index: 0 ---------------------------------------------------------------------------------------\n",
            "\n",
            "Fold index: 1 ---------------------------------------------------------------------------------------\n",
            "\n",
            "Fold index: 2 ---------------------------------------------------------------------------------------\n",
            "\n",
            "Fold index: 3 ---------------------------------------------------------------------------------------\n",
            "\n",
            "Fold index: 4 ---------------------------------------------------------------------------------------\n",
            "\n",
            "Fold index: 5 ---------------------------------------------------------------------------------------\n",
            "\n",
            "Fold index: 6 ---------------------------------------------------------------------------------------\n",
            "\n",
            "Fold index: 7 ---------------------------------------------------------------------------------------\n",
            "\n",
            "Fold index: 8 ---------------------------------------------------------------------------------------\n",
            "\n",
            "Fold index: 9 ---------------------------------------------------------------------------------------\n",
            "\n",
            "---------------------------------------------------------------------------------------\n",
            "Average results from 10-fold cross-validation\n",
            "in standardized units (mean 0, standard deviation 1)\n",
            "\n",
            "Method               Root mean-squared error\n",
            "DecisionTree_Regression        0.109926\n",
            "ExtraTrees_Regression          0.078293\n",
            "RandomForest_Regression        0.082774\n",
            "GradientBoosting_Regression    0.080902\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrKjc34cbRY6",
        "colab_type": "text"
      },
      "source": [
        "# Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhgaNOBbbRY8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "2f87aec7-d94d-4bcd-a233-83abc936c3e9"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Create a base model\n",
        "rf = RandomForestRegressor()\n",
        "\n",
        "# Create the parameter grid based on the results of random search \n",
        "param_grid = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [80, 90, 100, 110],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 200, 300, 1000]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 2)\n",
        "\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    8.3s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:   33.7s\n",
            "[Parallel(n_jobs=-1)]: Done 361 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=-1)]: Done 644 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=-1)]: Done 864 out of 864 | elapsed:  3.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
              "             estimator=RandomForestRegressor(bootstrap=True, criterion='mse',\n",
              "                                             max_depth=None,\n",
              "                                             max_features='auto',\n",
              "                                             max_leaf_nodes=None,\n",
              "                                             min_impurity_decrease=0.0,\n",
              "                                             min_impurity_split=None,\n",
              "                                             min_samples_leaf=1,\n",
              "                                             min_samples_split=2,\n",
              "                                             min_weight_fraction_leaf=0.0,\n",
              "                                             n_estimators='warn', n_jobs=None,\n",
              "                                             oob_score=False, random_state=None,\n",
              "                                             verbose=0, warm_start=False),\n",
              "             iid='warn', n_jobs=-1,\n",
              "             param_grid={'bootstrap': [True], 'max_depth': [80, 90, 100, 110],\n",
              "                         'max_features': [2, 3], 'min_samples_leaf': [3, 4, 5],\n",
              "                         'min_samples_split': [8, 10, 12],\n",
              "                         'n_estimators': [100, 200, 300, 1000]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTghMi-EbRZD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b4f5529f-cb35-4a45-910f-b9761035d195"
      },
      "source": [
        "def evaluate(model, test_features, test_labels):\n",
        "    predictions = model.predict(test_features)\n",
        "    errors = abs(predictions - test_labels)\n",
        "    mape = 100 * np.mean(errors / test_labels)\n",
        "    accuracy = 100 - mape\n",
        "    print('Model Performance')\n",
        "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
        "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
        "    \n",
        "    return accuracy\n",
        "\n",
        "print(grid_search.best_params_)\n",
        "best_grid = grid_search.best_estimator_\n",
        "grid_accuracy = evaluate(best_grid, X_test,y_test)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'bootstrap': True, 'max_depth': 90, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 100}\n",
            "Model Performance\n",
            "Average Error: 0.0609 degrees.\n",
            "Accuracy = 81.85%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiinWCC4bRZP",
        "colab_type": "text"
      },
      "source": [
        "# Let's Refit the Extra Trees Model and Check Feature Importance\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzcQoR0hbRZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=mydata5.iloc[:, 1:12].values\n",
        "y=mydata5.iloc[:,0].values    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwS8jMj3bRZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "myfit=ExtraTreesRegressor(n_estimators = 100, \n",
        "                          criterion='mse', \n",
        "                          max_features = 3, \n",
        "                          max_depth=100,\n",
        "                          bootstrap=True, \n",
        "                          min_samples_leaf=4,\n",
        "                          min_samples_split=8, \n",
        "                          n_jobs = -1, \n",
        "                          random_state = RANDOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhIs47ZnbRZk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9456dc2b-6695-407a-be5f-5b4eb8de1a40"
      },
      "source": [
        "myfit.fit(X,y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=100,\n",
              "                    max_features=3, max_leaf_nodes=None,\n",
              "                    min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                    min_samples_leaf=4, min_samples_split=8,\n",
              "                    min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
              "                    oob_score=False, random_state=1, verbose=0,\n",
              "                    warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWyZPgWobRZu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6960ffb7-2a84-4dea-dafa-67911b37a589"
      },
      "source": [
        "print(\"R^2=\",myfit.score(X,y)) # quick R^2\n",
        "pred= myfit.predict(X)\n",
        "rmse = sqrt(mean_squared_error(pred, y))\n",
        "print('RMSE=', rmse)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R^2= 0.7347572455403935\n",
            "RMSE= 0.09514584214825246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqlChDuUbRZ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "ef5dba55-fb90-4e01-a290-b805974f98b6"
      },
      "source": [
        "importances=myfit.feature_importances_\n",
        "std = np.std([myfit.feature_importances_ for tree in myfit.estimators_],\n",
        "             axis=0)\n",
        "indices = np.argsort(importances)[::-1]\n",
        "plt.figure()\n",
        "plt.title(\"Feature importances\")\n",
        "plt.barh(range(X.shape[1]), importances[indices],\n",
        "       color=\"r\", xerr=std[indices], align=\"center\")\n",
        "plt.yticks(range(X.shape[1]), indices)\n",
        "plt.ylim([-1, X.shape[1]])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-1, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Se8YKuEjbRZ-",
        "colab_type": "text"
      },
      "source": [
        "This completes the example for Module 4.\n",
        "\n"
      ]
    }
  ]
}